---

- name: "Check if {{ spark_tar_name }} exists"
  stat:
    path: "{{ spark_user_home }}/{{scala_tar_name }}"
  register:
    copiedSpark

- name: "Copy {{spark_tar_name}}"
  copy:
    src: "{{spark_tar_path}}"
    dest: "{{spark_user_home}}/{{spark_tar_name}}"
  ignore_errors: True
  when: not copiedSpark.stat.exists

- name: "Download Spark from {{spark_download_url}}"
  get_url:
    dest: "{{spark_user_name}}/{{spark_tar_name}}"
    url: "{{spark_download_url}}"
  when: not copiedSpark.stat.exists

- name: "Unpack {{ spark_tar_name }}"
  unarchive:
    copy: no
    src: "{{spark_user_home}}/{{spark_tar_name}}"
    dest: "{{spark_user_home}}"

  
- name: create spark log directory
  file:
    path: "{{spark_log_directory}}"
    state: directory

# - name: create hadoop native lib directory
#   file:
#     path: "{{spark_native_lib}}"
#     state: directory

- name: copy hadoop native lib
  copy:
    src: "{{hadoop_native_lib_path}}"
    dest: "{{spark_user_home}}"

- name: unarchive native hadoop lib
  unarchive:
    src: "{{spark_user_home}}/{{hadoop_native_lib}}"
    dest: "{{spark_user_home}}"
    copy: no

- name: config spark
  template:
    src: "{{item}}"
    dest: "{{spark_home}}/conf/"
  with_items:
    - ./conf/slaves
    - ./conf/spark-env.sh
    - ./conf/log4j.properties

- name: config spark-master.service
  template:
    src: spark-master.service
    dest: /etc/systemd/system/
    mode: 0700
  when: spark_is_master is defined and spark_is_master == "true"

- name: start-master when spark_is_master == true
  service:
    name: spark-master
    state: restarted
  when: spark_is_master is defined and spark_is_master == "true"

- name: config spark-slave.service
  template:
    src: spark-slave.service
    dest: /etc/systemd/system/
    mode: 0700
  when: spark_is_slave is defined and spark_is_slave == "true"

- name: start-slave when spark_is_slave == true
  service:
    name: spark-slave
    state: restarted
  when: spark_is_slave is defined spark_is_slave == "true"
