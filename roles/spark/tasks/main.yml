---

- name: create spark group
  group:
    name: "{{spark_group}}"
    system: yes
  tags:
    - spark

- name: create spark user
  user:
    name: "{{spark_user}}"
    group: "{{spark_group}}"
    system: yes
  tags:
    - spark

# - name: Create sparkâ€™s user folder in HDFS
#   shell: |
#     sudo -u {{}} hadoop fs -mkdir -p /user/{{spark_user}}
#     hadoop fs -chown -R {{spark_user}}:{{spark_group}} /user/{{spark_user}}

- name: "Copy {{spark_tar_name}}"
  copy:
    src: "{{configure_files_path}}/{{spark_tar_name}}"
    dest: "{{spark_user_home}}/{{spark_tar_name}}"
    owner: "{{spark_user}}"
    group: "{{spark_group}}"
  ignore_errors: no
  tags:
    - spark

- name: "Check if {{ spark_tar_name }} exists"
  stat:
    path: "{{ spark_user_home }}/{{spark_tar_name }}"
  register:
    is_spark_copied
  tags:
    - spark
  
- name: "Download Spark"
  get_url:
    dest: "{{spark_user_name}}/{{spark_tar_name}}"
    url: "{{spark_download_url}}"
    owner: "{{spark_user}}"
    group: "{{spark_group}}"
  when: not is_spark_copied.stat.exists
  tags:
    - spark

- name: "Unpack {{ spark_tar_name }}"
  unarchive:
    copy: no
    src: "{{spark_user_home}}/{{spark_tar_name}}"
    dest: "{{spark_user_home}}"
  tags:
    - spark

  
- name: create spark log directory
  file:
    path: "{{spark_log_directory}}"
    state: directory
    owner: "{{spark_user}}"
    group: "{{spark_group}}"
  tags:
    - spark

- name: create hadoop native lib directory
  file:
    path: "{{spark_native_lib}}"
    state: directory
    owner: "{{ spark_user }}"
    group: "{{ spark_group }}"
  tags:
    - spark

- name: copy hadoop native lib
  copy:
    src: "{{configure_files_path}}/{{hadoop_native_tar}}"
    dest: "{{spark_user_home}}"
    owner: "{{spark_user}}"
    group: "{{spark_group}}"
  tags:
    - spark

- name: unarchive native hadoop lib
  unarchive:
    src: "{{spark_user_home}}/{{hadoop_native_tar}}"
    dest: "{{spark_native_lib}}"
    owner: "{{spark_user}}"
    group: "{{spark_group}}"
    copy: no
  tags:
    - spark
    
- blockinfile:
    path: /etc/profile
    block: |
      export SPARK_HOME={{spark_home}}
      export PATH=$PATH:$SPARK_HOME/bin
  tags:
    - spark

- name: config spark
  template:
    src: "{{item}}"
    dest: "{{spark_home}}/conf/"
  with_items:
    - ./conf/slaves
    - ./conf/spark-env.sh
    - ./conf/log4j.properties
  tags:
    - spark

- name: config spark-master.service
  template:
    src: spark-master.service
    dest: /etc/systemd/system/
    mode: 0700
  when: spark_is_master is defined and spark_is_master == "true"

- name: start-master when spark_is_master == true
  service:
    name: spark-master
    state: restarted
  when: spark_is_master is defined and spark_is_master == "true"

- name: config spark-slave.service
  template:
    src: spark-slave.service
    dest: /etc/systemd/system/
    mode: 0700
  when: spark_is_slave is defined and spark_is_slave == "true"

- name: start-slave when spark_is_slave == true
  service:
    name: spark-slave
    state: restarted
  when: spark_is_slave is defined and spark_is_slave == "true"
